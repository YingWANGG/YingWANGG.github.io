---
---

@article{wang_2023_lifelongmemory,
  title={LifelongMemory: Leveraging LLMs for Answering Queries in Long-form Egocentric Videos},
  author={Wang, Ying and Yang, Yanlai and Ren, Mengye},
  journal={Preprint},
  year={2023},
  selected={true},
  abbr={arXiv},
  pdf={https://arxiv.org/pdf/2312.05269.pdf},
  website={https://lifelongmemory.github.io/},
  code={https://github.com/Agentic-Learning-AI-Lab/lifelong-memory},
  preview={lifelongmemory_thumbnail.png}
}

@InProceedings{wang_2023_visual,
  title={Visual Explanations of Image-Text Representations via Multi-Modal Information Bottleneck Attribution},
  author={Wang, Ying and Rudner, Tim G. J. and Wilson, Andrew Gordon},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023},
  selected={true},
  abbr={NeurIPS},
  pdf={https://openreview.net/pdf?id=ECvtxmVP0x},
  code={https://github.com/YingWANGG/M2IB/tree/main},
  preview={m2ib_thumbnail.png},
}

@InProceedings{Wang_2023_CVPR,
    author    = {Wang, Ying and Pfeiffer, Jonas and Carion, Nicolas and LeCun, Yann and Kamath, Aishwarya},
    title     = {Adapting Grounded Visual Question Answering Models to Low Resource Languages},
    booktitle = {CVPR Multimodal Learning and Applications Workshop [Oral]},
    month     = {June},
    year      = {2023},
    pages     = {2595-2604},
    selected = {true},
    abbr = {CVPRW},
    pdf = {https://openaccess.thecvf.com/content/CVPR2023W/MULA/html/Wang_Adapting_Grounded_Visual_Question_Answering_Models_to_Low_Resource_Languages_CVPRW_2023_paper.html},
    code = {https://github.com/YingWANGG/xMDETR},
    preview={xmdetr_thumbnail.png}
}
